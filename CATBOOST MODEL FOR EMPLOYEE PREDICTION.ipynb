{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMPLOYEE PROMOTION PREDICTION\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>By: OFINNI OLUWASEUN ABEL</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>PROBLEM DEFINITION AND FEATURES' DESCRIPTION<b/>\n",
    "       </div>\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>CASE STUDY</b>\n",
    "</div>\n",
    "\n",
    "**YAKUB TRADING GROUP - ALGORITHMIC STAFF PROMOTION**\n",
    "\n",
    "Abdullah’s Baba Yakub, 38, is the heir apparent to the highly revered Yakub business dynasty. The enterprise has spanned decades with vast investment interest in all the various sectors of the economy.\n",
    "\n",
    "Abdullah has worked for 16 years in Europe and America after his first and second degrees at Harvard University where he studied Engineering and Business Management. He is a very experienced technocrat and a global business leader who rose through the rank to become a Senior Vice President at a leading US business conglomerate.\n",
    "His dad is now 70 and has invited him to take over the company with a mandate to take it to the next level of growth as a sustainable legacy. Abdullah is trusted by his father and his siblings to lead this mandate.\n",
    "\n",
    "On resumption, he had an open house with the staff to share his vision and to listen to them on how to take the business to the next level. Beyond the general operational issues and increasing need for regulatory compliance, one of the issues raised by the staff was a general concern on the process of staff promotion. Many of the staff allege that it is skewed and biased. Abdullah understood the concern and promised to address it in a most scientific way.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>MAIN TASK</b>\n",
    "</div>\n",
    "    \n",
    "_**You have been called in by Abdullah to use your machine learning skills to study the pattern of promotion. With this insight, he can understand the important features among available features that can be used to predict promotion eligibility.**_\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>FEATURES DESCRIPTIONS</b>\n",
    "</div>\n",
    "    \n",
    "The dataset contains these variables as explained below:\n",
    "\n",
    "• **Employee No** : System-generated unique staff ID\n",
    "\n",
    "• **Division**: Operational department where each employee works\n",
    "\n",
    "• **Qualification**: Highest qualification received by the staff\n",
    "\n",
    "• **Gender**: Male or Female\n",
    "\n",
    "• **Channel of Recruitment**: How the staff was recruited – this is via internal process, use of an agent or special referral\n",
    "\n",
    "• **Trainings Attended** : Unique paid and unpaid trainings attended by each staff in the previous business cycle\n",
    "\n",
    "• **Year of birth**: Year that the employee was born\n",
    "\n",
    "• **Last Performance Score**: Previous year overall performance HR score and rated on a scale of 0-14\n",
    "\n",
    "• **Year of recruitment** : The year that each staff was recruited into the company\n",
    "\n",
    "• **Targets Met or KPI Met**: A measure of employees who meet the annual set target. If met, the staff scores 1 but if not, it is a 0.\n",
    "\n",
    "• **Previous Award** : An indicator of previous award won. If yes, it is a 1 and if No it is a 0.\n",
    "\n",
    "• **Training score average**: Feedback score on training attended based on evaluation\n",
    "\n",
    "• **State Of Origin**: The state that the employee claims\n",
    "\n",
    "• **Foreign Schooled**: An indicator of staff who had any of their post-secondary education outside the country. Responses are in Yes or No\n",
    "\n",
    "• **Marital Status**: Marriage status of employees and recorded as Yes or No\n",
    "\n",
    "• **Past Disciplinary Action** : An indicator if a staff has been summoned to a disciplinary panel in the past. This is indicated as Yes or No\n",
    "\n",
    "• **Previous Intra-Departmental Movement** : This is an indicator to identify staff who have moved between departments in the past. Yes and No are the responses.\n",
    "\n",
    "• **No of Previous Employers** : A list of the number of companies that an employee worked with before joining the organisation. This is recorded as counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def message():\n",
    "    print(\"\"\"Hey there! \n",
    "Your Codes Ran successfully! You may proceed.\"\"\")\n",
    "    \n",
    "message()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "     <center>\n",
    "<b>LOADING REQUIRED MODULES FOR THE PROJECT</b>\n",
    "     </center>   \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required package and libraries\n",
    "import pandas as pd #Dataframe handling\n",
    "import numpy as np # For handling the Maths and Stats operations\n",
    "import pandas_profiling as pp #To geberate a broad overview of my data\n",
    "\n",
    "#For Missing Values treatment. I'll prefer MinMaxScaler for scaling in this project due to the nature of distribution \n",
    "import missingno #For visualising the distribution of missing values based on counts strategy\n",
    "from sklearn.preprocessing import MinMaxScaler #For scaling our feature to range between 0 and 1\n",
    "\n",
    "#Visualisation tools imported from their libraries tfor this project\n",
    "# Standard plotly imports\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns \n",
    "%matplotlib inline #To make our plots appear directly in this notebook\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot, init_notebook_mode #The benefit of visual interactivity is huge\n",
    "# Using plotly + cufflinks in offline mode\n",
    "import cufflinks\n",
    "cufflinks.go_offline(connected=True)\n",
    "init_notebook_mode(connected=False)\n",
    "#I'll use IPython Core Interactive Shell to enable Multiple outputs per cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity=\"all\" #I'll set this to all to make my experiment seamless\n",
    "\n",
    "# The Classifier Algorithm for our experiment and other relevant modules\n",
    "from catboost import Pool, CatBoostClassifier #The raw guy is here waiting to be trained. It's a superstar, you know.\n",
    "from sklearn.ensemble import RandomForestClassifier #I'll prefer this to DecisionForest anyday.\n",
    "from sklearn.ensemble import GradientBoostingClassifier #A good member of the boosting family, I just hope it can handle this project\n",
    "from sklearn import model_selection #I'll import this, just in case I resort to selecting the best model\n",
    "from sklearn.metrics import (confusion_matrix,f1_score, recall_score, \n",
    "                             precision_score,accuracy_score) #The problem of imbalance class distribution is best measured using these metrics. It will be costly to use Accuracy\n",
    "from sklearn.model_selection import (StratifiedKFold, train_test_split, \n",
    "                                     KFold, cross_val_score, RandomizedSearchCV,GridSearchCV) #These slaves have work to do here too\n",
    "\n",
    "#We obviously don't want to keep getting that Red Box showing up in the experiment\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\") #We have ignored it now. So, we are good to go.\n",
    "\n",
    "message()#You know the feeling when your code complete with 0 error... smiles!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "     <center>\n",
    "<b>LOADING THE DATASETS FOR THIS PROJECT</b>\n",
    "      </center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-block alert-success'>\n",
    "\n",
    "<b>We have two Datasets for this project:\n",
    "    \n",
    "* Train Dataset: This contain the attributes that would be used and the target variable for our prediction problem.\n",
    "* Test Dataset: Here we have the attributes which are similar to what we have in the Train set with the exception of \n",
    "  Target variable \n",
    "  </b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the train data\n",
    "train=pd.read_csv('train.csv')\n",
    "\n",
    "#Load the test data\n",
    "test=pd.read_csv('test.csv')\n",
    "\n",
    "message()#winks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "     <center>\n",
    "<b>DESCRIPTIVE STATISTICS OF OUR DATA</b>\n",
    "      </center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data information: Get to know the data and thier types plus other info\n",
    "train.info()#\n",
    "test.info()\n",
    "\n",
    "#Accessing the data from the head and tail\n",
    "train.head(3)\n",
    "train.tail(3)\n",
    "\n",
    "test.head(3)\n",
    "test.tail(3)\n",
    "\n",
    "#Check the dimension of the train and test data\n",
    "'The train shape is- '+str(train.shape), 'The test shape is- '+str(test.shape)\n",
    "\n",
    "#Check the descriptive statistics of quantitative variables in our dataset\n",
    "train.describe()\n",
    "test.describe()\n",
    "\n",
    "message()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "     <center>\n",
    "<b>CHECKING FOR NULL OR MISSING VALUES IN OUR DATASET</b>\n",
    "      </center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for Null Values and then confirm their spreads in our dataset\n",
    "train.isnull().sum()\n",
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Let's verify the location of the missing data in our dataset, then we can visualise it.  \n",
    "missing_train = train[train.isnull().any(axis=1)]\n",
    "#Let's visualise the spread of the missing data in our train dataset to give us a clue of how best to deal with it.\n",
    "sns.heatmap(train.isnull(),yticklabels= False,cbar= False, cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The yellow lines indicates the pattern of the missing values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's verify the location of the missing data in our test set, then we can visualise it.\n",
    "missing_test = test[test.isnull().any(axis=1)]\n",
    "#Let's visualise the spread of the missing data in our train dataset to give us a clue of how best to deal with it.\n",
    "sns.heatmap(test.isnull(),yticklabels= False,cbar= False, cmap='viridis')\n",
    "\n",
    "message()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WHat went missing might be costlier. I'll check the number of promotions along the missing instances\n",
    "missing_train['Promoted_or_Not'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are dealing with imbalanced situations, every information counts but some count more. However, we don't know whose. I'll retain the missing values and find a way to fill them as I progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Let's take a deeper look into our dataset by checking the profile of each attribute and a quick overview with relevant tips to guide us.\n",
    "pp.ProfileReport(train)\n",
    "\n",
    "pp.ProfileReport(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What I have done by using this in interactive Pandas_Profiling is to basically give you a clear picture and descriptions of what we can expect in the process of analysis and building the predictive models for this project. The information presented are clear I assume."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <center>\n",
    "<b> UNIVARIATE VISUALISATIONS</b>\n",
    "    </center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Let's Visualise the target's (Promoted_or_Not) distribution\n",
    "train['Promoted_or_Not'].iplot(kind='hist', xTitle='Promotion (0=No, 1=Yes)',\n",
    "yTitle ='count', title='Distribution of Promotion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the Profile of 'State_of_Origin', there are 37 levels in the categorical variable. It's best practice, if we verify it's distribution by visualising it with an interactive plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <center>\n",
    "<b>MISSING DATA TREATMENTS</b>\n",
    "    </center>\n",
    "</div> \n",
    "\n",
    "* We have NaN as the missing values in Qulaification. The three levels I'm familiar with have been exhausted here, so, I'll replace the NaN by grouping by Division, Division should give us more information to fill the missing Qualification for the purpose of analysis and interpretations.\n",
    "\n",
    "* Note: I have tried other approaches of imputing missing values before resorting to this method, they seem to influence negatively the result of my model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many missing values are there in our dataset and how are they distributed?\n",
    "missingno.matrix(train, figsize = (15,9))\n",
    "missingno.bar(train, sort='descending', figsize = (15,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treating missing Data\n",
    "#imp = SimpleImputer(missing_values = np.nan, strategy = 'most_frequent')\n",
    "#train_df = pd.DataFrame(imp.fit_transform(train), columns=train.columns, index=train.index)\n",
    "#test_df = pd.DataFrame(imp.fit_transform(test), columns=test.columns, index=test.index)\n",
    "#test_df = test.fillna((test).mode().iloc[0]).astype('object') #interpolate(method='pad', limit_direction='both')\n",
    "\n",
    "train[\"Qualification\"] = train[\"Qualification\"].astype('object')\n",
    "train['Qualification'] = train.groupby([\"Division\"])[\"Qualification\"].apply(lambda x: x.fillna(x.value_counts().index[0]))\n",
    "\n",
    "test[\"Qualification\"] = test[\"Qualification\"].astype('object')\n",
    "test['Qualification'] = test.groupby([\"Division\"])[\"Qualification\"].apply(lambda x: x.fillna(x.value_counts().index[0]))\n",
    "\n",
    "#train_df = train.dropna()\n",
    "#test_df = test.fillna(method = \"ffill\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <center>\n",
    "<b>COPYING THE DATA TO NEW DATAFRAME</b>\n",
    "    </center>\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train.copy()) #The train data has been copied into tran_df\n",
    "test_df = pd.DataFrame(test.copy())   #The test data has been copied into test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's check the outcome of missing values filled\n",
    "train_df.Qualification.value_counts()\n",
    "test_df.Qualification.value_counts()\n",
    "\n",
    "print (\"There are no missing values anymore, we can go ahead with the project now\")\n",
    "sns.heatmap(train_df.isnull(),yticklabels= False,cbar= False, cmap='viridis')\n",
    "#sns.heatmap(test_df.isnull(),yticklabels= False,cbar= False, cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <center>\n",
    "<b>UNICARIATE VISUALISATION OF VARIABLES</b>\n",
    "    </center>\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"This is the distribution of Employee by Region of Origin in the Train Data\")\n",
    "#Check State's distribution\n",
    "train['State_Of_Origin'].iplot(kind='hist', xTitle='State of Origin',\n",
    "yTitle ='count', title='Employees States of Origin')\n",
    "\n",
    "print(\"This is the distribution of Employee by Region of Origin in the Test Data\")\n",
    "#Check State's distribution\n",
    "test['State_Of_Origin'].iplot(kind='hist', xTitle='State of Origin',\n",
    "yTitle ='count', title='Employees States of Origin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"This is the distribution of Employee by Gender in the Train Data\")\n",
    "#Check Gender distribution\n",
    "train['Gender'].iplot(kind='hist', xTitle=\"Employees' Gender\",\n",
    "yTitle ='count', title=\"Employees' Gender Distribution\")\n",
    "\n",
    "print(\"This is the distribution of Employee by Gender in the Test Data\")\n",
    "#Check Gender distribution\n",
    "test['Gender'].iplot(kind='hist', xTitle=\"Employees' Gender\",\n",
    "yTitle ='count', title=\"Employees' Gender Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"This is the distribution of Employee by Performance Score in the Train Data\")\n",
    "#Check Performance distribution\n",
    "train['Last_performance_score'].iplot(kind='hist', xTitle='Performance Score',\n",
    "yTitle ='count', title='Employees Last Performance Score')\n",
    "\n",
    "print(\"This is the distribution of Employee by Performance Score in the Test Data\")\n",
    "#Check Performance distribution\n",
    "test['Last_performance_score'].iplot(kind='hist', xTitle='Performance Score',\n",
    "yTitle ='count', title='Employees Last Performance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"This is the distribution of Employee by Average of Training Score in the Train Data\")\n",
    "#Check Averaged Training Scores' distribution\n",
    "train['Training_score_average'].iplot(kind='hist', xTitle= 'Average of Training Score',\n",
    "yTitle ='count', title='Employees Averaged Training Scores')\n",
    "\n",
    "print(\"This is the distribution of Employee by Average of Training Score in the Test Data\")\n",
    "#Check Averaged Training Scores' distribution\n",
    "test['Training_score_average'].iplot(kind='hist', xTitle= 'Average of Training Score',\n",
    "yTitle ='count', title='Employees Averaged Training Scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"This is the distribution of Employee by Average of Number of Trainin in the Train Data\")\n",
    "#Check Averaged Training Scores' distribution\n",
    "train['Trainings_Attended'].iplot(kind='hist', xTitle= 'Number of Training',\n",
    "yTitle ='count', title='Number of Past Trainings')\n",
    "\n",
    "print(\"This is the distribution of Employee by Average of Number of Trainin in the Test Data\")\n",
    "#Check Averaged Training Scores' distribution\n",
    "test['Trainings_Attended'].iplot(kind='hist', xTitle= 'Number of Training',\n",
    "yTitle ='count', title='Number of Past Trainings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"This is the distribution of Employee by Average of Educational Qualification in the Train Data\")\n",
    "#Check Qualification distribution. Note: NaN would not feature in the measurement\n",
    "train['Qualification'].iplot(kind='hist', xTitle= 'Educational Qualification',\n",
    "yTitle ='count', title='Level of Education')\n",
    "\n",
    "print(\"This is the distribution of Employee by Average of Educational Qualification in the Test Data\")\n",
    "#Ch#Check Qualification distribution. Note: NaN would not feature in the measurement\n",
    "test['Qualification'].iplot(kind='hist', xTitle= 'Educational Qualification',\n",
    "yTitle ='count', title='Level of Education')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <center>\n",
    "<b>SECURING MORE LEVEL OF DETAILS FROM EMPLOYEES RECENT PROMOTION USING OTHER ATTRIBUTES</b>\n",
    "    </center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <center>\n",
    "<b>Performnace Score And PRevious Award Assessment </b>\n",
    "    </center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.groupby([\"Previous_Award\"])['Last_performance_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this level of variation, Performance score motivated Previous Award received by employee. It will be good to check if this also triggers Promotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab([train_df.Previous_Award, train_df.Last_performance_score], train_df.Promoted_or_Not,  margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A large proportion of the employee that got Award eventually got Promoted. We can therefore expect these to be predictor of Employee Promotion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <center>\n",
    "<b>Targets Met, Training Score Average and Promotion of Employee Assessment and Visualisation </b>\n",
    "    </center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.groupby([\"Targets_met\"])['Training_score_average'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is slight difference in the mean Training Score Average of Employees that met targes and otherwise, I'll check for the variation in promotion below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab([train_df.Targets_met, train_df.Training_score_average], train_df.Promoted_or_Not, margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we go, Targets Met, Performance Score and Training Score Average  are strong predictors of Promotion in this regards. So, the model must account for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "KPI = pd.crosstab(train_df.Targets_met,train_df.Promoted_or_Not,normalize='index')\n",
    "KPI.plot.bar(stacked=True)\n",
    "plt.rcParams['figure.figsize'] = [5, 5]\n",
    "plt.legend(title='is_promoted',loc='upper left',bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <center>\n",
    "<b>Gender Based Promotion Assessment </b>\n",
    "    </center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stacked plot above reveals the importance of meeting targets beore an Employee could really qualify for Promotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [3, 5]\n",
    "Emp_Gender_pro = pd.crosstab(train_df.Gender,train_df.Promoted_or_Not,normalize='index')\n",
    "Emp_Gender_pro.plot.bar(stacked=True)\n",
    "plt.legend(title='is_promoted',loc='upper left',bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The organisation seems to hold equity at workplace very strongly in the area of promotion of their staffs. I might end up not using the Gender attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab([train_df.Gender, train_df.Division], train_df.Promoted_or_Not, margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as shown in the plot above, there are not variation in the percentage of Promotion across various Deparments in the organisation as far as Gender is concerned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <center>\n",
    "<b>DATA PREPROCESSING AND FEATURE ENGINEERING</b>\n",
    "    </center>\n",
    "</div> \n",
    "\n",
    "* I'll be dealing with all the categorical variables in the two Data Sets in this section.\n",
    "\n",
    "* Numerical variable that are not Normally distributed would be addressed here and I'll generate other varibales from their results if necessary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many States are there in our DAta\n",
    "\n",
    "train_df['State_Of_Origin'].value_counts().count()\n",
    "test_df['State_Of_Origin'].value_counts().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here I will create a Dictionary of State to get their geo-political zone, then we'll replace States with their Region \n",
    "Region = {\"BENUE\":\"North-Central\", \"KOGI\":\"North-Central\", \"KWARA\":\"North-Central\", \"NASSARAWA\":\"North-Central\",\n",
    "            \"NIGER\":\"North-Central\", \"PLATEAU\":\"North-Central\", \"FCT\":\"North-Central\", \"ADAMAWA\":\"North-East\", \"BAUCHI\":\"North-East\", \n",
    "            \"BORNO\":\"North-East\", \"GOMBE\":\"North-East\", \"TARABA\":\"North-East\", \"YOBE\":\"North-East\", \"JIGAWA\":\"North-West\",\"KADUNA\":\"North-West\", \n",
    "            \"KANO\":\"North-West\", \"KATSINA\":\"North-West\", \"KEBBI\":\"North-West\", \"SOKOTO\":\"North-West\", \"ZAMFARA\":\"North-West\", \"ABIA\":\"South-East\", \n",
    "            \"ANAMBRA\":\"South-East\", \"EBONYI\":\"South-East\", \"ENUGU\":\"South-East\", \"IMO\":\"South-East\", \"AKWA IBOM\":\"South-South\", \"BAYELSA\":\"South-South\",\n",
    "            \"CROSS RIVER\":\"South-South\", \"RIVERS\":\"South-South\", \"DELTA\":\"South-South\", \"EDO\":\"South-South\", \"EKITI\":\"South-West\", \"LAGOS\":\"South-West\",\n",
    "            \"OGUN\":\"South-West\", \"ONDO\":\"South-West\", \"OSUN\":\"South-West\", \"OYO\":\"South-West\"}\n",
    "\n",
    "data = [train_df, test_df]\n",
    "for dataset in data:\n",
    "    dataset['State_Of_Origin'] = dataset['State_Of_Origin'].map(Region).astype('category')\n",
    "\n",
    "test_df.head()\n",
    "\n",
    "print (\"I have done this to cut down computational cost and imcrease Model's effeciency and for effective analysis and interpretation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['State_Of_Origin'].iplot(kind='hist', xTitle=\"Region of Origin\" ,\n",
    "yTitle ='count', title=\"Distribution of Employees' Region of Origin\")\n",
    "\n",
    "test_df['State_Of_Origin'].iplot(kind='hist', xTitle=\"Region of Origin\" ,\n",
    "yTitle ='count', title=\"Distribution of Employees' Region of Origin\")\n",
    "message()\n",
    "print(\"\"\"This is the distribution of Employee based on their Region of Origin. \n",
    "You can get realtime count of their distribution by hovering your pointer over the plot.\n",
    "\n",
    "You can drill down using the tools available at the right hand top-corner of the plot.\n",
    "\n",
    "The Plots show that, there are more Employees South-Western Region than every other region. \n",
    "We will understand the Channel that the majority of these Employee got recruited from later.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = (18, 14)\n",
    "sns.set_style('whitegrid')\n",
    "fig, ax = plt.subplots(figsize = ps)\n",
    "sns.countplot(ax=ax, x='State_Of_Origin',hue='Promoted_or_Not',data=train_df,palette='rainbow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df[\"State_Of_Origin\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "    <center>\n",
    "<b>CONVERTING OBJECT TYPE TO CATEGORY</b>\n",
    "    </center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "data = [train_df, test_df]\n",
    "for dataset in data:\n",
    "    dataset[\"Qualification\"] = dataset[\"Qualification\"].astype(\"category\")\n",
    "test_df[\"Qualification\"].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(test_df.isnull(),yticklabels= False,cbar= False, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [train_df, test_df]\n",
    "for dataset in data:\n",
    "    dataset[\"Gender\"] = dataset[\"Gender\"].astype(\"category\")\n",
    "test_df[\"Gender\"].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [train_df, test_df]\n",
    "for dataset in data:\n",
    "    dataset[\"Channel_of_Recruitment\"] = dataset[\"Channel_of_Recruitment\"].astype(\"category\")\n",
    "test_df[\"Channel_of_Recruitment\"].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [train_df, test_df]\n",
    "for dataset in data:\n",
    "    dataset[\"No_of_previous_employers\"] = dataset[\"No_of_previous_employers\"].astype(\"category\")\n",
    "test_df[\"No_of_previous_employers\"].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Employment_History = {'0' : 0, '1' : 1, '2': 2, '3': 3, '4': 4, '5' : 5, 'More than 5': 6}\n",
    "\n",
    "data = [train_df, test_df]\n",
    "for dataset in data:\n",
    "    dataset['No_of_previous_employers'] = dataset['No_of_previous_employers'].map(Employment_History)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ps = (16, 10)\n",
    "sns.set_style('whitegrid')\n",
    "fig, ax = plt.subplots(figsize = ps)\n",
    "sns.countplot(ax=ax, x='Past_Disciplinary_Action',hue='Promoted_or_Not',data=train_df,palette='rainbow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Employee with no previous disciplinary actions got more promoted. This should be a predictor as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "    <center>\n",
    "<b>GENERATING NEW VARIABLES FROM OUR QUANTITATIVE VARIABLE</b>\n",
    "    </center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Based on the distribution of the recruitment year and the Birth-Year. I'll create a new variable that tells me the Age of Employee at the time of employment\n",
    "train_df['Age_at_Employment'] = list (train_df['Year_of_recruitment'])-(train_df['Year_of_birth']).astype('int')\n",
    "test_df['Age_at_Employment'] = list (test_df['Year_of_recruitment'])-(test_df['Year_of_birth']).astype('int')\n",
    "\n",
    "test_df.head()\n",
    "message()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Based on the distribution of the recruitment year and the Birth-Year. I'll create a new variable that tells me the length of service with the company and i'll bin it to categories\n",
    "train_df['length_of_service'] = 2019 - train['Year_of_recruitment']\n",
    "test_df['length_of_service'] = 2019 - test['Year_of_recruitment']\n",
    "\n",
    "#I will release it from this current cell now\n",
    "#train_df.drop(['Year_of_recruitment'], axis=1, inplace=True)\n",
    "#test_df.drop(['Year_of_recruitment'], axis=1, inplace=True)\n",
    "test_df.tail()\n",
    "\n",
    "message()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <center>\n",
    "<b>VISUALISATION OF VARIABLES RELATIONSHIPS</b>\n",
    "    </center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ps = (18, 14)\n",
    "sns.set_style('whitegrid')\n",
    "fig, ax = plt.subplots(figsize = ps)\n",
    "sns.countplot(ax=ax, x='Age_at_Employment',hue='Promoted_or_Not',data=train_df,palette='RdBu_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = (18, 14)\n",
    "sns.set_style('whitegrid')\n",
    "fig, ax = plt.subplots(figsize = ps)\n",
    "sns.countplot(ax=ax, x='Gender',hue='Previous_Award',data=train_df,palette='RdBu_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binning Age at the time of Recruitment into categories\n",
    "bins_1 = np.linspace(min(train_df[\"Last_performance_score\"]), max(train_df[\"Last_performance_score\"]), 3)\n",
    "bins_2 = np.linspace(min(test_df[\"Last_performance_score\"]), max(test_df[\"Last_performance_score\"]), 3)\n",
    "\n",
    "#We group the result with these categories\n",
    "group_names = ['Low', 'High']\n",
    "train_df['Binned_Score'] = pd.cut(train_df['Last_performance_score'], bins_1, labels=group_names, include_lowest=True )\n",
    "test_df['Binned_Score'] = pd.cut(test_df['Last_performance_score'], bins_2, labels=group_names, include_lowest=True )\n",
    "\n",
    "#train_df.drop(['Last_performance_score'], axis=1, inplace=True)\n",
    "#test_df.drop(['Last_performance_score'], axis=1, inplace=True)\n",
    "\n",
    "#Let's Visualise the Bins\n",
    "test_df['Binned_Score'].iplot(kind='hist', xTitle='Binned Last Performance Score',\n",
    "yTitle ='count', title='Last Performance Score of Employee')\n",
    "\n",
    "ex_1 = pd.get_dummies(train_df[\"Binned_Score\"])\n",
    "ex_2 = pd.get_dummies(test_df[\"Binned_Score\"])\n",
    "\n",
    "ex_1.rename(columns={'Low':'Low_PS', 'High':'High_PS'}, inplace=True)\n",
    "ex_2.rename(columns={'Low':'Low_PS', 'High':'High_PS'}, inplace=True)\n",
    "\n",
    "# merge data  and \"ex_1\" and \"ex_2\" accordingly\n",
    "train_df = pd.concat([train_df, ex_1], axis=1)\n",
    "test_df = pd.concat([test_df, ex_2], axis=1)\n",
    "\n",
    "# drop original column \"Binned_Score\"\n",
    "train_df.drop(\"Binned_Score\", axis = 1, inplace=True)\n",
    "test_df.drop(\"Binned_Score\", axis = 1, inplace=True)\n",
    "\n",
    "test_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <center>\n",
    "<b>FURTHER DRILL INTO THE DATA</b>\n",
    "    </center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab([train_df.Previous_Award, train_df.No_of_previous_employers], train_df.Promoted_or_Not, margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab([train_df.Previous_Award, train_df.Training_score_average], train_df.Promoted_or_Not, margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab([train_df.Qualification, train_df.Targets_met], train_df.Promoted_or_Not, margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab([train_df.Trainings_Attended, train_df.Training_score_average], train_df.Promoted_or_Not, margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab([train.Marital_Status, train_df.Targets_met], train_df.Promoted_or_Not, margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab([train_df.State_Of_Origin, train_df.Age_at_Employment], train_df.Promoted_or_Not, margins=True)                                                                                                                                                                                                                                                                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.crosstab([train_df.Previous_IntraDepartmental_Movement, train_df.Targets_met], train_df.Promoted_or_Not, margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab([train_df.Division, train_df.Qualification], train_df.Promoted_or_Not, margins=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <div class=\"alert alert-block alert-success\">\n",
    "    <center>\n",
    "<b>MORE FEATURE GENERATION</b>\n",
    "    </center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df[\"Training_score_rec\"] = np.where(((train_df[\"Training_score_average\"]>=39) & (train_df[\"Targets_met\"]==1)),1,0)\n",
    "train_df[\"Targets_Met_Reward\"] = np.where(((train_df[\"Targets_met\"]==1) & (train_df[\"Previous_Award\"]==1)),1,0)\n",
    "#train_df[\"Gold_Employee\"] = np.where(((train_df[\"Trainings_Attended\"]<=6) & (train_df['Training_score_average']<=65)), 1,0)\n",
    "#train_df[\"Targets_Met_Reward\"] = np.where(((train[\"Last_performance_score\"]>=5.0) & (train[\"Targets_met\"]==1)),1,0)\n",
    "#train_df[\"High_Potential\"] = np.where(((train_df[\"Previous_Award\"]>=0) & (train_df[\"length_of_service\"]<=23)),1,0)\n",
    "\n",
    "\n",
    "#test_df[\"Training_score_rec\"] = np.where(((test_df[\"Training_score_average\"]>=39) & (test_df[\"Targets_met\"]==1)),1,0)\n",
    "test_df[\"Targets_Met_Reward\"] = np.where(((test_df[\"Targets_met\"]==1) & (test_df[\"Previous_Award\"]==1)),1,0)\n",
    "#test_df['Gold_employee'] = np.where(((test_df[\"Trainings_Attended\"]<=6) & (test_df['Training_score_average']<=65)), 1,0)                                                                          \n",
    "#test_df[\"Targets_Met_Reward\"] = np.where(((test_df[\"Last_performance_score\"]>=5.0) & (test_df[\"Targets_met\"]==1)),1,0)\n",
    "#test_df[\"High_Potential\"] = np.where(((test_df[\"Previous_Award\"]>=0) & (test_df[\"length_of_service\"]<=23)),1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp_1 = pd.get_dummies(train_df[\"Qualification\"])\n",
    "exp_2 = pd.get_dummies(test_df[\"Qualification\"])\n",
    "\n",
    "exp_1.rename(columns={'Qualification-First Degree or HND':'First Degree or HND',\n",
    "                        'Qualification-MSc, MBA and PhD':'MSc, MBA and PhD',\n",
    "                        'Qualification-Non-University Education':'Non-University Education', \n",
    "                        'Qualification-Unknown': 'Unknown'}, inplace=True)\n",
    "exp_2.rename(columns={'Qualification-First Degree or HND':'First Degree or HND', \n",
    "                        'Qualification-MSc, MBA and PhD':'MSc, MBA and PhD',\n",
    "                        'Qualification-Non-University Education':'Non-University Education', \n",
    "                        'Qualification-Unknown': 'Unknown'}, inplace=True)\n",
    "\n",
    "# merge data  and \"exp_1\" and \"exp_2\" accordingly\n",
    "train_df = pd.concat([train_df, exp_1], axis=1)\n",
    "test_df = pd.concat([test_df, exp_2], axis=1)\n",
    "\n",
    "# drop original column \"Qualification\" from the the two sets\n",
    "train_df.drop(\"Qualification\", axis = 1, inplace=True)\n",
    "test_df.drop(\"Qualification\", axis = 1, inplace=True)\n",
    "\n",
    "test_df.tail()\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [train_df, test_df]\n",
    "for dataset in data:\n",
    "    dataset['Division'] = dataset['Division']\n",
    "\n",
    "exp_1 = pd.get_dummies(train_df[\"Division\"])\n",
    "exp_2 = pd.get_dummies(test_df[\"Division\"])\n",
    "\n",
    "exp_1.rename(columns={'Division-Commercial Sales and Marketing':'Commercial Sales and Marketing',\n",
    "                        'Division-Sourcing and Purchasing':'Sourcing and Purchasing',\n",
    "                        'Division-Information Technology and Solution Support':'Information Technology and Solution Support',\n",
    "                        'Division-Information and Strategy':\"Information and Strategy\",\n",
    "                        'Division-Business Finance Operations': \"Business Finance Operations\",\n",
    "                        'Division-People/HR Management':\"People/HR Management\",\n",
    "                        'Division-Regulatory and Legal services':\"Regulatory and Legal services\",\n",
    "                        'Division-Research and Innovation':\"Research and Innovation\",\n",
    "                        'Division-Customer Support and Field Operations':\"Customer Support and Field Operations\" \n",
    "                       }, inplace=True)\n",
    "exp_2.rename(columns={'Division-Commercial Sales and Marketing':'Commercial Sales and Marketing',\n",
    "                        'Division-Sourcing and Purchasing':'Sourcing and Purchasing',\n",
    "                        'Division-Information Technology and Solution Support':'Information Technology and Solution Support',\n",
    "                        'Division-Information and Strategy':\"Information and Strategy\",\n",
    "                        'Division-Business Finance Operations': \"Business Finance Operations\",\n",
    "                        'Division-People/HR Management':\"People/HR Management\",\n",
    "                        'Division-Regulatory and Legal services':\"Regulatory and Legal services\",\n",
    "                        'Division-Research and Innovation':\"Research and Innovation\",\n",
    "                        'Division-Customer Support and Field Operations':\"Customer Support and Field Operations\" \n",
    "                       }, inplace=True)\n",
    "\n",
    "# merge data  and \"exp_1\" and \"exp_2\" accordingly\n",
    "train_df = pd.concat([train_df, exp_1], axis=1)\n",
    "test_df = pd.concat([test_df, exp_2], axis=1)\n",
    "\n",
    "# drop original column \"Qualification\" from the the two sets\n",
    "train_df.drop(\"Division\", axis = 1, inplace=True)\n",
    "test_df.drop(\"Division\", axis = 1, inplace=True)\n",
    "\n",
    "test_df.tail()\n",
    "train_df.info()\n",
    "message()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <div class=\"alert alert-block alert-info\">\n",
    "    <center>\n",
    "<b>DROPPING SOME FEATURES AT THIS LEVEL</b>\n",
    "    </center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop([\"EmployeeNo\", \"Gender\", \"Channel_of_Recruitment\", \"Trainings_Attended\",\n",
    "              \"Year_of_birth\", \"Last_performance_score\",\"Year_of_recruitment\", \"State_Of_Origin\",\n",
    "              \"Marital_Status\",\"No_of_previous_employers\", \"Promoted_or_Not\", \"length_of_service\"], axis=1, inplace=True)\n",
    "\n",
    "test_df.drop([\"EmployeeNo\", \"Gender\", \"Channel_of_Recruitment\", \"Trainings_Attended\",\n",
    "               \"Year_of_birth\", \"Last_performance_score\",\"Year_of_recruitment\", \"State_Of_Origin\",\n",
    "               \"Marital_Status\", \"No_of_previous_employers\",\"length_of_service\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df['Foreign_schooled'] = train_df['Foreign_schooled'] .astype('category')\n",
    "test_df['Foreign_schooled'] = test_df['Foreign_schooled'] .astype('category')\n",
    "train_df.Previous_IntraDepartmental_Movement = train_df.Previous_IntraDepartmental_Movement.astype('category')\n",
    "test_df.Previous_IntraDepartmental_Movement = test_df.Previous_IntraDepartmental_Movement.astype('category')\n",
    "train_df.Past_Disciplinary_Action = train_df.Past_Disciplinary_Action.astype('category')\n",
    "test_df.Past_Disciplinary_Action = test_df.Past_Disciplinary_Action.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <center>\n",
    "<b>FEATURE SCALING USING MinMaxScaler</b>\n",
    "    </center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaling_tool = MinMaxScaler(feature_range=(0, 1), copy=True)\n",
    "columns = ['Training_score_average', 'Age_at_Employment']\n",
    "#For Train\n",
    "train_df[columns] = pd.DataFrame(scaling_tool.fit_transform(train_df[columns].values))\n",
    "test_df[columns] = pd.DataFrame(scaling_tool.transform(test_df[columns].values))\n",
    "\n",
    "test_df.head()\n",
    "#For Test\n",
    "#col_to_scale_2 = test_df[columns]\n",
    "#test_df.columns = scaling_tool.transform(col_to_scale_2, , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_train = pd.DataFrame(train_df.copy())\n",
    "#clean_test = pd.DataFrame(train_df.copy())\n",
    "label_names=['Foreign_schooled', \"Past_Disciplinary_Action\", \"Previous_IntraDepartmental_Movement\"]\n",
    "train_df= pd.get_dummies(train_df, columns=label_names,prefix=['Foreign_schooled', \"Past_Disciplinary_Action\", \n",
    "                                                               \"Previous_IntraDepartmental_Movement\"], drop_first=True)\n",
    "test_df= pd.get_dummies(test_df, columns=label_names, prefix=['Foreign_schooled', \"Past_Disciplinary_Action\", \n",
    "                                                             \"Previous_IntraDepartmental_Movement\"], drop_first=True)\n",
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train.Promoted_or_Not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_df, target,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=121, stratify=target) # I'm setting the seed here\n",
    "\n",
    "X_val, X_val_test, y_val, y_val_test = train_test_split(X_test, y_test,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=121, stratify=y_test)\n",
    "X_train.shape, X_test.shape, X_val.shape, X_val_test.shape\n",
    "message()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <center>\n",
    "<b>USING RANDOMSEARCH CROSS-VALIDATION TO TUNE THE PARAMETERS OF CATBOOST</b>\n",
    "    </center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(loss_function='Logloss')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "grid = {'learning_rate': [0.03, 0.1],\n",
    "        'depth': [4, 6, 10],\n",
    "        'l2_leaf_reg': [1, 3, 5, 7, 9]}\n",
    "\n",
    "randomized_search_result = model.randomized_search(grid,\n",
    "                                                   X=X_train,\n",
    "                                                   y=y_train,\n",
    "                                                   plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THE  SEARCH TOOK LONG TIME BEFORE COMPLETION DUE TO SYSTEM ISSUE. SO, I MODIFIED THE OUTPUT OF ITS PARAMETER TO TRAIN AND TEST. CHECK BELOW FOR OUTCOMES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <center>\n",
    "<b>MODEL TRAINING, VALIDATION AND PREDICTION</b>\n",
    "    </center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, eval_set=(X_val, y_val), use_best_model=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val_t = model.predict(X_val_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy = accuracy_score(y_val_test,pred_val_t)\n",
    "F1_score = f1_score(y_val_test,pred_val_t)\n",
    "precision = precision_score(y_val_test,pred_val_t)\n",
    "recall = recall_score(y_val_test,pred_val_t)\n",
    "cm = confusion_matrix(y_val_test,pred_val_t)\n",
    "\n",
    "print(Accuracy, F1_score, precision, recall)\n",
    "print (cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_test_ca = cb_model.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "        \"EmployeeNo\": test[\"EmployeeNo\"],\n",
    "        \"Promoted_or_Not\":pred_test_ca.astype('int')\n",
    "    })\n",
    "\n",
    "submission.to_csv('New_Pred_Cat.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <center>\n",
    "<b>USING GridSearch CROSS-VALIDATION TO TUNE THE PARAMETERS OF RandomForestClassifier</b>\n",
    "    </center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_jobs=-1, random_state=0,class_weight='balanced',n_estimators=100,bootstrap=True, max_depth=80)\n",
    "#forest = GradientBoostingClassifier(loss='exponential',max_features='auto')\n",
    "param_grid = {\n",
    "    'n_estimators': [200,500,800]\n",
    "}\n",
    "grid_search = GridSearchCV(estimator = forest, param_grid = param_grid,cv = 3, n_jobs = -1, verbose = 2)\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "feature_importance = {}\n",
    "for i in range(len(X_train.columns)):\n",
    "    feature_importance[X_train.columns[i]] = feature_importances[i]\n",
    "importance_df = pd.DataFrame(list(feature_importance.items()),columns=['feature','importance'])\n",
    "importance_df = importance_df.sort_values('importance',ascending=False)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.rcParams['figure.figsize'] = [18, 11]\n",
    "sns.barplot(x=\"feature\",y=\"importance\",data=importance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above Plots of feaure of Importance,(Training_average_score, Age at EMployment, Targets Met, Previous Award, Commercial and Sales Marketing and some others provided more information for our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = grid_search.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1_score(y_val, pred)\n",
    "'f1 score - '+str(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <center>\n",
    "<b>USING GridSearch CROSS-VALIDATION TO TUNE THE PARAMETERS OF GradientBoostingClassifier</b>\n",
    "    </center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forest = RandomForestClassifier(n_jobs=-1, random_state=0,class_weight='balanced',n_estimators=100,bootstrap=True, max_depth=80)\n",
    "forest = GradientBoostingClassifier(loss='exponential',max_features='auto')\n",
    "param_grid = {\n",
    "    'n_estimators': [200,500,800]\n",
    "}\n",
    "grid_search = GridSearchCV(estimator = forest, param_grid = param_grid,cv = 3, n_jobs = -1, verbose = 2)\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "feature_importance = {}\n",
    "for i in range(len(X_train.columns)):\n",
    "    feature_importance[X_train.columns[i]] = feature_importances[i]\n",
    "importance_df = pd.DataFrame(list(feature_importance.items()),columns=['feature','importance'])\n",
    "importance_df = importance_df.sort_values('importance',ascending=False)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.rcParams['figure.figsize'] = [18, 10]\n",
    "sns.barplot(x=\"feature\",y=\"importance\",data=importance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above Plots of feaure of Importance,(Training_average_score, Targets Met, Previous Award, Commercial and Sales Marketing and some others provided more information for our Model.  Age at EMployment at seems to provide little infomation than it was for RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = grid_search.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1_score(y_val, pred)\n",
    "'f1 score - '+str(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = grid_search.predict(X_val_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1_score(y_val_test, pred)\n",
    "'f1 score - '+str(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_val_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <center>\n",
    "<b>Second Round of Hyperparameter Tuning for Gradient Boosting Classifier</b>\n",
    "    </center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = GradientBoostingClassifier(loss='exponential',max_features='auto', criterion = \"friedman_mse\")\n",
    "param_grid = {'learning_rate':[0.3, 0.2],\n",
    "    'n_estimators': [800,1000]\n",
    "}\n",
    "grid_search = GridSearchCV(estimator = forest, param_grid = param_grid,cv = 3, n_jobs = -1, verbose = 2)\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ = grid_search.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1_score(y_val, pred_)\n",
    "'f1 score - '+str(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "feature_importance = {}\n",
    "for i in range(len(X_train.columns)):\n",
    "    feature_importance[X_train.columns[i]] = feature_importances[i]\n",
    "importance_df = pd.DataFrame(list(feature_importance.items()),columns=['feature','importance'])\n",
    "importance_df = importance_df.sort_values('importance',ascending=False)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.rcParams['figure.figsize'] = [18, 11]\n",
    "sns.barplot(x=\"feature\",y=\"importance\",data=importance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slight improvements was witnessed after the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_gbm = grid_search.predict(test_df).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "        \"EmployeeNo\": test[\"EmployeeNo\"],\n",
    "        \"Promoted_or_Not\": test_pred_gbm\n",
    "    })\n",
    "\n",
    "submission.to_csv('GBM_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_tuned = GradientBoostingClassifier(criterion='friedman_mse', init=None, learning_rate=0.2,\n",
    "                                                  loss='exponential', max_depth=3, max_features='auto',max_leaf_nodes=None,\n",
    "                                                  min_impurity_decrease=0.0, min_impurity_split=None,min_samples_leaf=2,\n",
    "                                                  min_samples_split=3, min_weight_fraction_leaf=0.0, n_estimators=2000,\n",
    "                                                  n_iter_no_change=None, presort='auto', random_state=None,subsample=1.0, tol=0.0001,\n",
    "                                                  validation_fraction=0.1, verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <center>\n",
    "<b>AT THIS POINT, I STARTED MODIFYING CATBOOST PARAMETERS</b>\n",
    "    </center>\n",
    "</div>\n",
    "**I had to do this because of the parameter search time required is much due to the fact that I have HotEncoded the features thereby increasing the time to train model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## THE MODEL BELOW ACHIEVED 0.94603 ON THE LEADERBOARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_model = CatBoostClassifier(iterations=800,\n",
    "                             learning_rate=0.1,\n",
    "                             depth=10,\n",
    "                             eval_metric='F1',\n",
    "                             random_seed = 42,\n",
    "                             bagging_temperature = 0.23,\n",
    "                             od_type='Iter',l2_leaf_reg = 3,random_strength = 0.2,\n",
    "                             metric_period = 70,\n",
    "                             od_wait=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_new_cat = cb_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1_score(y_val, pred_new_cat)\n",
    "'f1 score - '+str(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_cat = cb_model.predict(test_df).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "        \"EmployeeNo\": test[\"EmployeeNo\"],\n",
    "        \"Promoted_or_Not\": test_pred_cat\n",
    "    })\n",
    "\n",
    "submission.to_csv('CAT_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.Promoted_or_Not.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <center>\n",
    "<b>The Model below Achieved PUB-0.9502 and PRI-0.9411 on the Leaderboard</b>\n",
    "    </center>\n",
    "</div>\n",
    "\n",
    "THIS IS THE PREFERED MODEL AND I WILL RECOMMEND THIS THAN THE MODEL BELOW WHICH I ENDED UP WITH ON THE PRIVATE LEADERBOARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_model_2 = CatBoostClassifier(iterations=1000,\n",
    "                             learning_rate=0.11,\n",
    "                             depth=10,\n",
    "                             eval_metric='F1',\n",
    "                             random_seed = 42,\n",
    "                             bagging_temperature = 0.25,\n",
    "                             od_type='Iter',l2_leaf_reg = 4,random_strength = 0.3,\n",
    "                             metric_period = 50,\n",
    "                             od_wait=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_model_2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_new_ca = cb_model_2.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1_score(y_val, pred_new_ca)\n",
    "'f1 score - '+str(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_val, pred_new_ca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_cat_2 = cb_model_2.predict(test_df).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "        \"EmployeeNo\": test[\"EmployeeNo\"],\n",
    "        \"Promoted_or_Not\": test_pred_cat_2\n",
    "    })\n",
    "\n",
    "submission.to_csv('CAT_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <center>\n",
    "<b>THE LAST CATBOOST MODEL</b>\n",
    "    </center>\n",
    "</div>\n",
    "\n",
    "**This Model achieved 0.94664 on the Public Leaderboard and 0.940680 on the Private Leaderboard**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_model_3 = CatBoostClassifier(iterations=831,\n",
    "                             learning_rate=0.19,\n",
    "                             depth=8,\n",
    "                             eval_metric='F1',\n",
    "                             random_seed = 99,\n",
    "                             bagging_temperature = 0.2,\n",
    "                             od_type='Iter',l2_leaf_reg = 4,random_strength = 0.25,\n",
    "                             metric_period = 60,\n",
    "                             od_wait=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_model_3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_new_c = cb_model_3.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1_score(y_val, pred_new_c)\n",
    "'f1 score - '+str(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_val, pred_new_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_new_c1 = cb_model_3.predict(X_val_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1_score(y_val_test, pred_new_c1)\n",
    "'f1 score - '+str(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_val_test, pred_new_c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_cat_3 = cb_model_3.predict(test_df).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "        \"EmployeeNo\": test[\"EmployeeNo\"],\n",
    "        \"Promoted_or_Not\": test_pred_cat_3\n",
    "    })\n",
    "\n",
    "submission.to_csv('CAT_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <center>\n",
    "<b>I STRONGLY BELIEVE THAT WITH MORE DATA, THE PREFERED MODEL WILL PERFORM BETTER</b>\n",
    "    </center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <center>\n",
    "<b> THANKS FOR THE OPPORTUNITY TO LEARN AND BECOME BETTER WITH MORE PRACTICE</b>\n",
    "    </center>\n",
    "</div>\n",
    "\n",
    "I must confess that this competition turtured me more than the way I actually turtured the Data. I look forward to meeting you all at the Boot Camp.\n",
    "Thanks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
